{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3bc54-660c-4c14-8a61-232da9958378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import joblib\n",
    "import logging\n",
    "from typing import List\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import logging\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set options to show full DataFrame output\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import joblib, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from typing import Any, Dict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "def no_risk_over_ride(df_std_2):\n",
    "    # =====================================================\n",
    "    # APPLY LLM \"No Risk\" OVERRIDE INTO NEW COLUMNS\n",
    "    # =====================================================\n",
    "    def apply_llm_no_risk_overrides(df, llm_col=\"evidence_text\",out_llm_col=\"updated_evidence_text\"):\n",
    "        \"\"\"\n",
    "        Creates updated_* columns based on llm_explanation.\n",
    "        Rule: If the text contains 'No Risk' (any case), set ALL updated columns to 'No Risk';\n",
    "              else keep the existing/original values.\n",
    "    \n",
    "        New columns created:\n",
    "          - updated_risk_level\n",
    "          - updated_main_risk_scenario\n",
    "          - updated_sub_risk_1\n",
    "          - updated_sub_risk_2\n",
    "          - updated_impact_1\n",
    "          - updated_impact_2\n",
    "          - updated_impact_3\n",
    "        \"\"\"\n",
    "        if llm_col not in df.columns:\n",
    "            raise KeyError(f\"Column '{llm_col}' not found in DataFrame.\")\n",
    "    \n",
    "        # 1) Build a mask: does LLM text say \"No Risk\" anywhere? (case-insensitive)\n",
    "        #    \\s* allows \"No   Risk\" or line breaks between the words.\n",
    "        mask_no_risk = df[llm_col].astype(str).str.contains(r\"\\bno\\s*risk\\b\", case=False, na=False)\n",
    "    \n",
    "        # 2) Map of original -> new updated columns\n",
    "        col_map = {\n",
    "            \"risk_level\":          \"updated_risk_level\",\n",
    "            \"main_risk_scenario\":  \"updated_main_risk_scenario\",\n",
    "            \"sub_risk_1\":          \"updated_sub_risk_1\",\n",
    "            \"sub_risk_2\":          \"updated_sub_risk_2\",\n",
    "            \"impact_1\":            \"updated_impact_1\",\n",
    "            \"impact_2\":            \"updated_impact_2\",\n",
    "            \"impact_3\":            \"updated_impact_3\",\n",
    "            \n",
    "        }\n",
    "    \n",
    "        # 3) Initialize updated_* columns with existing/original values\n",
    "        for old_col, new_col in col_map.items():\n",
    "            if old_col not in df.columns:\n",
    "                df[old_col] = pd.NA\n",
    "            df[new_col] = df[old_col]\n",
    "    \n",
    "        # 4) Override to \"No Risk\" wherever the LLM text contains \"No Risk\"\n",
    "        for new_col in col_map.values():\n",
    "            df.loc[mask_no_risk, new_col] = \"No Risk\"\n",
    "    \n",
    "         # Build updated_llm_explanation\n",
    "        df[out_llm_col] = df[llm_col]\n",
    "        df.loc[mask_no_risk, out_llm_col] = \"There is No Risk for this line item.\"\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    # ---------- Example usage ----------\n",
    "    # After you've built df_std[\"llm_explanation\"]:\n",
    "    # df_std = build_word_style_explanations(df_std, dest_col=\"llm_explanation\")\n",
    "    df_updated = apply_llm_no_risk_overrides(df_std_2.copy(), llm_col=\"evidence_text\")\n",
    "    \n",
    "    return df_updated\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
