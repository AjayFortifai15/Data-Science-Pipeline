{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a059e2df-b099-4731-9617-f95c06a3ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajayn\\AppData\\Local\\Temp\\ipykernel_23772\\1632847627.py:117: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  summary_multi = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import psycopg2\n",
    "# ---- choose the severities you want ----\n",
    "severities = [\"no risk\", \"high risk\", \"needs validation\", \"very high risk\"]  # case-insensitive\n",
    "sev_array_sql = \",\".join([f\"'{s}'\" for s in severities])\n",
    "\n",
    "query = f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    lower(risk_severity)  AS risk_severity,\n",
    "    risk_category,\n",
    "    risk_definition,\n",
    "    -- counts\n",
    "    COALESCE(txn_count_24h,0)::numeric AS c_24h,\n",
    "    COALESCE(txn_count_3d,0)::numeric  AS c_3d,\n",
    "    COALESCE(txn_count_7d,0)::numeric  AS c_7d,\n",
    "    COALESCE(txn_count_1m,0)::numeric  AS c_1m,\n",
    "    COALESCE(txn_count_3m,0)::numeric  AS c_3m,\n",
    "    COALESCE(txn_count_6m,0)::numeric  AS c_6m,\n",
    "    -- amounts\n",
    "    COALESCE(txn_amt_24h,0)::numeric   AS a_24h,\n",
    "    COALESCE(txn_amt_3d,0)::numeric    AS a_3d,\n",
    "    COALESCE(txn_amt_7d,0)::numeric    AS a_7d,\n",
    "    COALESCE(txn_amt_1m,0)::numeric    AS a_1m,\n",
    "    COALESCE(txn_amt_3m,0)::numeric    AS a_3m,\n",
    "    COALESCE(txn_amt_6m,0)::numeric    AS a_6m\n",
    "  FROM semantic_db.vw_risk_summary_by_severity_category_and_def_6m\n",
    "  WHERE risk_definition IS NOT NULL\n",
    "    AND risk_definition !~* '^overall$'\n",
    "    AND lower(risk_severity) = ANY(ARRAY[{sev_array_sql}])\n",
    "),\n",
    "exploded AS (\n",
    "  SELECT risk_severity, risk_category, risk_definition, win, cnt, amt\n",
    "  FROM (\n",
    "    SELECT risk_severity, risk_category, risk_definition, '24h' AS win, c_24h AS cnt, a_24h AS amt FROM base\n",
    "    UNION ALL SELECT risk_severity, risk_category, risk_definition, '3d',  c_3d,  a_3d  FROM base\n",
    "    UNION ALL SELECT risk_severity, risk_category, risk_definition, '7d',  c_7d,  a_7d  FROM base\n",
    "    UNION ALL SELECT risk_severity, risk_category, risk_definition, '1m',  c_1m,  a_1m  FROM base\n",
    "    UNION ALL SELECT risk_severity, risk_category, risk_definition, '3m',  c_3m,  a_3m  FROM base\n",
    "    UNION ALL SELECT risk_severity, risk_category, risk_definition, '6m',  c_6m,  a_6m  FROM base\n",
    "  ) u\n",
    "),\n",
    "agg_def AS (\n",
    "  SELECT\n",
    "    risk_severity,\n",
    "    win,\n",
    "    risk_category,\n",
    "    risk_definition,\n",
    "    SUM(cnt) AS def_cnt,\n",
    "    SUM(amt) AS def_amt\n",
    "  FROM exploded\n",
    "  GROUP BY risk_severity, win, risk_category, risk_definition\n",
    ")\n",
    "SELECT\n",
    "  risk_severity,\n",
    "  win,\n",
    "  -- severity totals across all categories\n",
    "  SUM(def_cnt) AS severity_total_count,\n",
    "  SUM(def_amt) AS severity_total_amount,\n",
    "\n",
    "  -- Dynamic category (No Risk -> 'No Risk', else 'Procurement Risk')\n",
    "  SUM(def_cnt) FILTER (\n",
    "    WHERE risk_category ILIKE\n",
    "      CASE WHEN lower(risk_severity) = 'no risk' THEN 'no risk' ELSE 'procurement risk' END\n",
    "  ) AS category_count,\n",
    "  SUM(def_amt) FILTER (\n",
    "    WHERE risk_category ILIKE\n",
    "      CASE WHEN lower(risk_severity) = 'no risk' THEN 'no risk' ELSE 'procurement risk' END\n",
    "  ) AS category_amount,\n",
    "\n",
    "  -- Within chosen category: per risk_definition maps\n",
    "  jsonb_object_agg(risk_definition, def_cnt)\n",
    "    FILTER (WHERE risk_category ILIKE\n",
    "      CASE WHEN lower(risk_severity) = 'no risk' THEN 'no risk' ELSE 'procurement risk' END\n",
    "    ) AS category_by_definition_counts,\n",
    "\n",
    "  jsonb_object_agg(risk_definition, def_amt)\n",
    "    FILTER (WHERE risk_category ILIKE\n",
    "      CASE WHEN lower(risk_severity) = 'no risk' THEN 'no risk' ELSE 'procurement risk' END\n",
    "    ) AS category_by_definition_amounts\n",
    "\n",
    "FROM agg_def\n",
    "GROUP BY risk_severity, win\n",
    "ORDER BY\n",
    "  CASE win WHEN '24h' THEN 1 WHEN '3d' THEN 2 WHEN '7d' THEN 3\n",
    "           WHEN '1m'  THEN 4 WHEN '3m' THEN 5 WHEN '6m' THEN 6 END,\n",
    "  CASE risk_severity\n",
    "    WHEN 'no risk' THEN 1\n",
    "    WHEN 'high risk' THEN 2\n",
    "    WHEN 'needs validation' THEN 3\n",
    "    WHEN 'very high risk' THEN 4\n",
    "    ELSE 99\n",
    "  END;\n",
    "\"\"\"\n",
    "\n",
    "#conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "#\t\t\tdatabase='baldota-dev-db',\n",
    "#\t\t\tuser='fortifai_ng_user_ro',\n",
    "#\t\t\tpassword='user@123!',\n",
    "#\t\t\tport='5432',\n",
    "#            sslmode=\"require\"\n",
    "#\t\t)\n",
    "\n",
    "conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "    \t\t\tdatabase='baldota-dev-db',\n",
    "    \t\t\tuser='fortifai_ng_ai_user_rw',\n",
    "    \t\t\tpassword='AIPwd@123!',\n",
    "    \t\t\tport='5432',\n",
    "                sslmode=\"require\"\n",
    "    \t\t)\n",
    "cur = conn.cursor()\n",
    "# make this transaction read-only\n",
    "conn.set_session(readonly=True)        # start session as read-only\n",
    "try:\n",
    "    summary_multi = pd.read_sql_query(query, conn)\n",
    "finally:\n",
    "    conn.commit()                      # or conn.rollback()\n",
    "    conn.set_session(readonly=False)   # now safe\n",
    "\n",
    "\n",
    "# Parse JSONB to dicts if strings\n",
    "for col in [\"category_by_definition_counts\", \"category_by_definition_amounts\"]:\n",
    "    summary_multi[col] = summary_multi[col].apply(lambda x: json.loads(x) if isinstance(x, str) and x else (x or {}))\n",
    "\n",
    "# ---- Helpers ----\n",
    "def fmt_int(x):\n",
    "    try:\n",
    "        v = float(x)\n",
    "        if not math.isfinite(v): return \"0\"\n",
    "        return f\"{int(round(v)):,}\"\n",
    "    except:\n",
    "        return \"0\"\n",
    "\n",
    "def fmt_amt(x):\n",
    "    try:\n",
    "        v = float(x)\n",
    "        if not math.isfinite(v): return \"0.00\"\n",
    "        return f\"{v:,.2f}\"\n",
    "    except:\n",
    "        return \"0.00\"\n",
    "\n",
    "def fmt_pct(n, d):\n",
    "    try:\n",
    "        n = float(n); d = float(d)\n",
    "        if d <= 0 or not math.isfinite(n) or not math.isfinite(d):\n",
    "            return \"0.00%\"\n",
    "        return f\"{(n/d)*100:,.2f}%\"\n",
    "    except:\n",
    "        return \"0.00%\"\n",
    "\n",
    "def fmt_outof(n, d, kind=\"int\"):\n",
    "    if kind == \"int\":\n",
    "        return f\"{fmt_int(n)} of {fmt_int(d)}\"\n",
    "    else:\n",
    "        return f\"{fmt_amt(n)} of {fmt_amt(d)}\"\n",
    "\n",
    "def nice_sev(s: str) -> str:\n",
    "    s = (s or \"\").lower()\n",
    "    if s == \"high risk\": return \"High Risk\"\n",
    "    if s == \"needs validation\": return \"Needs Validation\"\n",
    "    if s == \"very high risk\": return \"Very High Risk\"\n",
    "    if s == \"no risk\": return \"No Risk\"\n",
    "    return s.title()\n",
    "\n",
    "def category_for_severity(sev_label: str) -> str:\n",
    "    return \"No Risk\" if sev_label == \"No Risk\" else \"Procurement Risk\"\n",
    "\n",
    "summary_multi[\"sev_label\"] = summary_multi[\"risk_severity\"].apply(nice_sev)\n",
    "\n",
    "# Orders\n",
    "win_order = [\"24h\", \"3d\", \"7d\", \"1m\", \"3m\", \"6m\"]\n",
    "sev_order = [\"High Risk\", \"Needs Validation\", \"Very High Risk\", \"No Risk\"]\n",
    "preferred_defs = [\"No Risk\", \"Price Variance Risk\", \"Split PO\"]\n",
    "\n",
    "# Ensure numerics\n",
    "for col in [\"severity_total_count\", \"severity_total_amount\", \"category_count\", \"category_amount\"]:\n",
    "    summary_multi[col] = pd.to_numeric(summary_multi[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Index for quick lookup\n",
    "summary_multi.set_index([\"win\", \"sev_label\"], inplace=True)\n",
    "\n",
    "# Window totals (for % of window)\n",
    "win_totals = summary_multi.groupby(level=0)[[\"severity_total_count\", \"severity_total_amount\"]].sum()\n",
    "win_total_cnt = win_totals[\"severity_total_count\"].to_dict()\n",
    "win_total_amt = win_totals[\"severity_total_amount\"].to_dict()\n",
    "\n",
    "# Build the summary text for each (win, severity) with dynamic category + percentages + \"x of y\"\n",
    "def build_text(win, sev):\n",
    "    cat = category_for_severity(sev)  # 'Procurement Risk' or 'No Risk'\n",
    "\n",
    "    if (win, sev) not in summary_multi.index:\n",
    "        return (f\"[{win}] [{sev}] Total: 0 of 0 (0.00% of window, \"\n",
    "                f\"amount 0.00 of 0.00 — 0.00% of window); \"\n",
    "                f\"{cat}: 0 of 0 (0.00% of {sev}, amount 0.00 of 0.00 — 0.00% of {sev}). \"\n",
    "                f\"Within {cat} — counts → —; amounts → —\")\n",
    "\n",
    "    r = summary_multi.loc[(win, sev)]\n",
    "\n",
    "    total_cnt = r[\"severity_total_count\"]\n",
    "    total_amt = r[\"severity_total_amount\"]\n",
    "    cat_cnt   = r[\"category_count\"]\n",
    "    cat_amt   = r[\"category_amount\"]\n",
    "\n",
    "    # Window totals\n",
    "    w_cnt = win_total_cnt.get(win, 0)\n",
    "    w_amt = win_total_amt.get(win, 0)\n",
    "\n",
    "    # %s\n",
    "    pct_sev_of_win_cnt = fmt_pct(total_cnt, w_cnt)\n",
    "    pct_sev_of_win_amt = fmt_pct(total_amt, w_amt)\n",
    "    pct_cat_of_sev_cnt = fmt_pct(cat_cnt, total_cnt)\n",
    "    pct_cat_of_sev_amt = fmt_pct(cat_amt, total_amt)\n",
    "\n",
    "    # Definitions within the chosen category\n",
    "    by_def_c = r[\"category_by_definition_counts\"] or {}\n",
    "    by_def_a = r[\"category_by_definition_amounts\"] or {}\n",
    "\n",
    "    keys = [k for k in preferred_defs if k in by_def_c] + [k for k in by_def_c if k not in preferred_defs]\n",
    "\n",
    "    if keys and cat_cnt > 0:\n",
    "        parts_c = [f\"{k}: {fmt_outof(by_def_c.get(k, 0), cat_cnt, 'int')} ({fmt_pct(by_def_c.get(k, 0), cat_cnt)})\"\n",
    "                   for k in keys]\n",
    "    else:\n",
    "        parts_c = [\"—\"]\n",
    "\n",
    "    if keys and float(cat_amt) > 0:\n",
    "        parts_a = [f\"{k}: {fmt_outof(by_def_a.get(k, 0), cat_amt, 'amt')} ({fmt_pct(by_def_a.get(k, 0), cat_amt)})\"\n",
    "                   for k in keys]\n",
    "    else:\n",
    "        parts_a = [\"—\"]\n",
    "\n",
    "    return (\n",
    "        f\"[{win}] [{sev}] \"\n",
    "        f\"Total: {fmt_outof(total_cnt, w_cnt, 'int')} ({pct_sev_of_win_cnt} of window, \"\n",
    "        f\"amount {fmt_outof(total_amt, w_amt, 'amt')} — {pct_sev_of_win_amt} of window); \"\n",
    "        f\"{cat}: {fmt_outof(cat_cnt, total_cnt, 'int')} ({pct_cat_of_sev_cnt} of {sev}, \"\n",
    "        f\"amount {fmt_outof(cat_amt, total_amt, 'amt')} — {pct_cat_of_sev_amt} of {sev}). \"\n",
    "        f\"Within {cat} — counts → \" + \", \".join(parts_c) +\n",
    "        \"; amounts → \" + \", \".join(parts_a)\n",
    "    )\n",
    "\n",
    "# Assemble the grid: rows=time windows, cols=severities, cells=summary text\n",
    "data = {sev: [build_text(win, sev) for win in win_order] for sev in sev_order}\n",
    "summary_text_grid = pd.DataFrame(data, index=win_order)\n",
    "\n",
    "# Optional: a single-column dataframe with merged summaries per window\n",
    "def merge_window(df, window, severities):\n",
    "    if window not in df.index:\n",
    "        return \"\"\n",
    "    cols = [c for c in severities if c in df.columns]\n",
    "    parts = []\n",
    "    for c in cols:\n",
    "        val = df.at[window, c] if c in df.columns else \"\"\n",
    "        if pd.notna(val) and str(val).strip():\n",
    "            parts.append(str(val).strip())\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "all_merged = {w: merge_window(summary_text_grid, w, sev_order) for w in win_order}\n",
    "all_summaries_df = pd.DataFrame({\"All Summary\": [all_merged[w] for w in win_order]}, index=win_order)\n",
    "\n",
    "# Outputs:\n",
    "# - summary_text_grid : main table with \"x of y\" + percentages\n",
    "# - all_summaries_df  : one-column merged summaries per time window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e753d6b2-fd04-4fee-ab39-073a19965fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24h</th>\n",
       "      <td>[24h] [High Risk] Total: 0 of 0 (0.00% of wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d</th>\n",
       "      <td>[3d] [High Risk] Total: 0 of 0 (0.00% of windo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d</th>\n",
       "      <td>[7d] [High Risk] Total: 0 of 0 (0.00% of windo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1m</th>\n",
       "      <td>[1m] [High Risk] Total: 141 of 833 (16.93% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3m</th>\n",
       "      <td>[3m] [High Risk] Total: 801 of 7,057 (11.35% o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6m</th>\n",
       "      <td>[6m] [High Risk] Total: 1,500 of 15,007 (10.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           All Summary\n",
       "24h  [24h] [High Risk] Total: 0 of 0 (0.00% of wind...\n",
       "3d   [3d] [High Risk] Total: 0 of 0 (0.00% of windo...\n",
       "7d   [7d] [High Risk] Total: 0 of 0 (0.00% of windo...\n",
       "1m   [1m] [High Risk] Total: 141 of 833 (16.93% of ...\n",
       "3m   [3m] [High Risk] Total: 801 of 7,057 (11.35% o...\n",
       "6m   [6m] [High Risk] Total: 1,500 of 15,007 (10.00..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc3526b-2110-4f33-ac75-abaa491e50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6m] [High Risk] Total: 1,500 of 15,007 (10.00% of window, amount 1,114,898,726.69 of 9,344,758,056.20 — 11.93% of window); Procurement Risk: 1,500 of 1,500 (100.00% of High Risk, amount 1,114,898,726.69 of 1,114,898,726.69 — 100.00% of High Risk). Within Procurement Risk — counts → Price Variance Risk: 1,432 of 1,500 (95.47%), Split PO: 68 of 1,500 (4.53%); amounts → Price Variance Risk: 622,233,705.10 of 1,114,898,726.69 (55.81%), Split PO: 492,665,021.59 of 1,114,898,726.69 (44.19%)\n",
      "\n",
      "[6m] [Needs Validation] Total: 264 of 15,007 (1.76% of window, amount 1,257,366,782.74 of 9,344,758,056.20 — 13.46% of window); Procurement Risk: 264 of 264 (100.00% of Needs Validation, amount 1,257,366,782.74 of 1,257,366,782.74 — 100.00% of Needs Validation). Within Procurement Risk — counts → Price Variance Risk: 264 of 264 (100.00%); amounts → Price Variance Risk: 1,257,366,782.74 of 1,257,366,782.74 (100.00%)\n",
      "\n",
      "[6m] [Very High Risk] Total: 745 of 15,007 (4.96% of window, amount 2,172,108,085.29 of 9,344,758,056.20 — 23.24% of window); Procurement Risk: 745 of 745 (100.00% of Very High Risk, amount 2,172,108,085.29 of 2,172,108,085.29 — 100.00% of Very High Risk). Within Procurement Risk — counts → Price Variance Risk: 733 of 745 (98.39%), Split PO: 12 of 745 (1.61%); amounts → Price Variance Risk: 1,846,339,085.29 of 2,172,108,085.29 (85.00%), Split PO: 325,769,000.00 of 2,172,108,085.29 (15.00%)\n",
      "\n",
      "[6m] [No Risk] Total: 12,498 of 15,007 (83.28% of window, amount 4,800,384,461.48 of 9,344,758,056.20 — 51.37% of window); No Risk: 12,498 of 12,498 (100.00% of No Risk, amount 4,800,384,461.48 of 4,800,384,461.48 — 100.00% of No Risk). Within No Risk — counts → No Risk: 12,498 of 12,498 (100.00%); amounts → No Risk: 4,800,384,461.48 of 4,800,384,461.48 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "high_24h_summary = all_summaries_df.loc[\"6m\", \"All Summary\"]\n",
    "print(high_24h_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585eb38-e824-4d70-868b-d7be712b2b7f",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "ai_summary = (\n",
    "    \"\"\"In the last 6 months, FortifAI’s AI engine SARA™ analyzed 15,007 transactions (≈8.98B total value). Risk mix: High Risk 10.12% (1,518), Very High Risk 4.98% (748), Needs Validation 6.88% (1,033), and No Risk 78.02% (11,708). Procurement-related activity accounts for 3,299 / 15,007 transactions (21.98%) and ≈7.75B / 8.98B in value (86.32%).\n",
    "\n",
    "Within Procurement by count: Price Variance Risk 3,058 / 3,299 (92.70%), Split PO 83 / 3,299 (2.52%), and No Risk 158 / 3,299 (4.79%).\n",
    "\n",
    "Within Procurement by value: Price Variance Risk ≈6.38B / 7.75B (82.37%), Split PO ≈0.81B / 7.75B (10.51%), and No Risk ≈0.55B / 7.75B (7.12%).\n",
    "\n",
    "These insights highlight where reviews should focus and support early risk mitigation across procurement operations.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df = pd.DataFrame([{\n",
    "    # meta\n",
    "    \"ai_summary\": ai_summary,\n",
    "    \"time_range_filter\": \"Last 6 Months\",\n",
    "}])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff613950-941d-44f9-a29a-b28e6565b541",
   "metadata": {},
   "source": [
    "ai_summary = \"\"\"In the last 6 months, FortifAI’s AI engine SARA™ analyzed 15,007 transactions (≈ ₹8.98B total value). Risk mix by count: High Risk 9.99% (1,500), Very High Risk 4.96% (745), Needs Validation 1.76% (264), and No Risk 83.28% (12,498).\n",
    "\n",
    "Procurement-related activity accounts for 2,509 / 15,007 transactions (16.72%) and ≈ ₹4.53B / ₹8.98B in value (50.51%).\n",
    "\n",
    "Within Procurement by count: Price Variance Risk 2,429 / 2,509 (96.81%) and Split PO 80 / 2,509 (3.19%).\n",
    "Within Procurement by value: Price Variance Risk ≈ ₹3.72B / ₹4.53B (82.04%) and Split PO ≈ ₹0.81B / ₹4.53B (17.96%).\n",
    "\n",
    "These insights point to Price Variance as the dominant driver by both count and value, suggesting review efforts should prioritize price-variance cases first, with targeted checks on Split PO activity.\n",
    "\"\"\"\n",
    "#conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "#\t\t\tdatabase='baldota-dev-db',\n",
    "#\t\t\tuser='fortifai_ng_user_ro',\n",
    "#\t\t\tpassword='user@123!',\n",
    "#\t\t\tport='5432',\n",
    "#            sslmode=\"require\"\n",
    "#\t\t)\n",
    "\n",
    "conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "    \t\t\tdatabase='baldota-dev-db',\n",
    "    \t\t\tuser='fortifai_ng_ai_user_rw',\n",
    "    \t\t\tpassword='AIPwd@123!',\n",
    "    \t\t\tport='5432',\n",
    "                sslmode=\"require\"\n",
    "    \t\t)\n",
    "\n",
    "cur = conn.cursor()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO transform_db.ai_summary_history (ai_summary, time_range_filter)\n",
    "        VALUES (%s, %s);\n",
    "    \"\"\", (ai_summary, \"Last 6 Months\"))  # or \"Last 6 Months\"\n",
    "    #new_id = cur.fetchone()[0]\n",
    "conn.commit()\n",
    "print(\"Inserted row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064e4661-5929-4a12-a488-9c0f0bcc9427",
   "metadata": {},
   "source": [
    "ai_summary = \"\"\"In the last 6 months, FortifAI’s AI engine SARA™ analyzed 15,007 transactions (≈ ₹8.98B total value). Risk mix by count: High Risk 9.99% (1,500), Very High Risk 4.96% (745), Needs Validation 1.76% (264), and No Risk 83.28% (12,498).\n",
    "\n",
    "Procurement-related activity accounts for 2,509 / 15,007 transactions (16.72%) and ≈ ₹4.53B / ₹8.98B in value (50.51%).\n",
    "\n",
    "Within Procurement by count: Price Variance Risk 2,429 / 2,509 (96.81%) and Split PO 80 / 2,509 (3.19%).\n",
    "Within Procurement by value: Price Variance Risk ≈ ₹3.72B / ₹4.53B (82.04%) and Split PO ≈ ₹0.81B / ₹4.53B (17.96%).\n",
    "\n",
    "These insights point to Price Variance as the dominant driver by both count and value, suggesting review efforts should prioritize price-variance cases first, with targeted checks on Split PO activity.\n",
    "\"\"\"\n",
    "#conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "#\t\t\tdatabase='baldota-dev-db',\n",
    "#\t\t\tuser='fortifai_ng_user_ro',\n",
    "#\t\t\tpassword='user@123!',\n",
    "#\t\t\tport='5432',\n",
    "#            sslmode=\"require\"\n",
    "#\t\t)\n",
    "\n",
    "conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "    \t\t\tdatabase='baldota-dev-db',\n",
    "    \t\t\tuser='fortifai_ng_ai_user_rw',\n",
    "    \t\t\tpassword='AIPwd@123!',\n",
    "    \t\t\tport='5432',\n",
    "                sslmode=\"require\"\n",
    "    \t\t)\n",
    "cur = conn.cursor()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        INSERT INTO transform_db.ai_summary_history (ai_summary, time_range_filter)\n",
    "        VALUES (%s, %s);\n",
    "    \"\"\", (ai_summary, \"Last 6 Months\"))  # or \"Last 6 Months\"\n",
    "    #new_id = cur.fetchone()[0]\n",
    "conn.commit()\n",
    "print(\"Inserted row\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4f07b-78a5-481c-b98b-eccfff094d00",
   "metadata": {},
   "source": [
    "#conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "#\t\t\tdatabase='baldota-dev-db',\n",
    "#\t\t\tuser='fortifai_ng_user_ro',\n",
    "#\t\t\tpassword='user@123!',\n",
    "#\t\t\tport='5432',\n",
    "#            sslmode=\"require\"\n",
    "#\t\t)\n",
    "\n",
    "conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "    \t\t\tdatabase='baldota-dev-db',\n",
    "    \t\t\tuser='fortifai_ng_ai_user_rw',\n",
    "    \t\t\tpassword='AIPwd@123!',\n",
    "    \t\t\tport='5432',\n",
    "                sslmode=\"require\"\n",
    "    \t\t)\n",
    "cur = conn.cursor()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        DELETE FROM transform_db.ai_summary_history\n",
    "WHERE ctid IN (\n",
    "  SELECT ctid\n",
    "  FROM transform_db.ai_summary_history\n",
    "  ORDER BY ctid DESC\n",
    "  LIMIT 1\n",
    ");\n",
    "    \"\"\")  # or \"Last 6 Months\"\n",
    "    #new_id = cur.fetchone()[0]\n",
    "conn.commit()\n",
    "print(\"Deleted row\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FortifEnv",
   "language": "python",
   "name": "fortifenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
