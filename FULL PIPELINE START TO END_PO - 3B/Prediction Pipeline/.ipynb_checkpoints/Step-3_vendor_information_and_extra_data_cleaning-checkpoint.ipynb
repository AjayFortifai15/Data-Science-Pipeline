{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a7193d-18f2-400a-94ba-b6dabebc101e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2119615917.py, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 60\u001b[1;36m\u001b[0m\n\u001b[1;33m    def vendor_information_and_extra_data_cleaning():\u001b[0m\n\u001b[1;37m                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "##############################################################################\n",
    "#  Cell 1 â€” Imports & common paths\n",
    "##############################################################################\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import joblib\n",
    "import logging\n",
    "from typing import List\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import logging\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set options to show full DataFrame output\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import joblib, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from typing import Any, Dict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def vendor_information_and_extra_data_cleaning(final_result_df):\n",
    "    ## cleaning .0 from vendor\n",
    "    s = final_result_df['vendor_or_creditor_acct_no_hpd_po'].astype(str).str.strip()           # ensure string & tidy spaces\n",
    "    mask = s.str.upper().eq('UNKNOWN')                 # rows to leave as-is\n",
    "    final_result_df['vendor_or_creditor_acct_no_hpd_po'] = s.where(mask, s.str.replace(r'\\.0$', '', regex=True))\n",
    "    \n",
    "    ## getting vendor name from vendor master DB\n",
    "    conn = psycopg2.connect(host='fortifai-ng-dev-db.postgres.database.azure.com',\n",
    "    \t\t\tdatabase='baldota-dev-db',\n",
    "    \t\t\tuser='fortifai_ng_user_ro',\n",
    "    \t\t\tpassword='user@123!',\n",
    "    \t\t\tport='5432',\n",
    "                sslmode=\"require\"\n",
    "    \t\t)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "                SELECT table_name \n",
    "                FROM information_schema.tables \n",
    "            \"\"\")\n",
    "    tables = [row[0] for row in cur.fetchall()]\n",
    "    vendor_data= pd.read_sql_query(f\"SELECT * FROM ingest_db.{'vendor_master_general_section'}\", conn)\n",
    "    a=pd.merge(final_result_df,vendor_data[['vendor_or_creditor_acct_no','vendor_name_1']],left_on='vendor_or_creditor_acct_no_hpd_po',right_on='vendor_or_creditor_acct_no',how='left')\n",
    "    # single or multiple\n",
    "    a = a.drop(columns=[\"vendor_or_creditor_acct_no\"], errors=\"ignore\")  # errors='ignore' skips missing cols\n",
    "    a['vendor_name_1'] = a['vendor_name_1'].fillna('UNKNOWN')\n",
    "    cols = [\n",
    "            'p2o_unit_conv_denom_src_po','o2b_unit_conv_denom_src_po',\n",
    "            'p2o_unit_conv_num_src_po','o2b_unit_conv_num_src_po',\n",
    "            'material_no_src_po','matl_group_src_po','exchange_rate_hpd_po',\n",
    "    \n",
    "            'principal_purch_agrmt_item_no_src_po','principal_purch_agrmt_no_hpd_po'\n",
    "        ]\n",
    "    a[cols] = (a[cols].astype(\"string\")\n",
    "                         .apply(lambda s: s.str.replace(r'(?<=\\d)\\.0+$', '', regex=True))\n",
    "                         .fillna(\"\"))\n",
    "    #a.shape\n",
    "    final_result_df_2=a.copy()\n",
    "    return final_result_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806c64d-f06a-41ed-ac5e-cce7286d6332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
