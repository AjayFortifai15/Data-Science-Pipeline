{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a085c3-3a8b-4dff-b580-f5ac6bdfeb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "# ============================================\n",
    "# FortifAI — Verification + Word-style 5 Sections (Markdown tables)\n",
    "# ============================================\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import joblib\n",
    "import logging\n",
    "from typing import List\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import logging\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set options to show full DataFrame output\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import joblib, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from typing import Any, Dict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evidence_part_1(final_result_df_2):\n",
    "    # =====================================================\n",
    "    # CONFIG\n",
    "    # =====================================================\n",
    "    SPLIT_WINDOW_DAYS    = 60\n",
    "    MAX_LINES_PER_RULE   = 50\n",
    "    CURRENCY_MUST_MATCH  = True\n",
    "    EPS_ZERO_DELTA_PCT   = 0.0  # treat |Δ%| <= EPS as \"zero\" (exclude)\n",
    "    \n",
    "    # NEW: hide empty subsections (that would otherwise print \"No Risk\")\n",
    "    HIDE_NO_RISK_SUBSECTIONS = True\n",
    "    \n",
    "    # Doc-type exclusions\n",
    "    DOC_TYPE_EXCLUDE_70 = {\n",
    "        \"NULL\",\"AN\",\"AR\",\"MN\",\"QC\",\"QI\",\"QS\",\"RS\",\"SC\",\"SG\",\"SR\",\"SS\",\"ST\",\"TP\",\"TR\",\"UB\",\"WK\"\n",
    "    }\n",
    "    DOC_TYPE_EXCLUDE_6768 = {\n",
    "        \"NULL\",\"AN\",\"AR\",\"MN\",\"QC\",\"QI\",\"QS\",\"RS\",\"SC\",\"SG\",\"SR\",\"SS\",\"ST\",\"TP\",\"TR\",\"UB\",\"WK\",\n",
    "        \"FO\",\"RS1\",\"RS2\",\"RS3\",\"RS4\",\"PS1\",\"PS2\",\"PS3\",\"PS4\",\"ZSB\"\n",
    "    }\n",
    "    \n",
    "    # =====================================================\n",
    "    # SYNONYMS & STANDARDIZATION\n",
    "    # =====================================================\n",
    "    COL_SYNONYMS = {\n",
    "        \"purch_doc_no_src_po\":            [\"purch_doc_no_src_po\", \"po_no\", \"purch_doc_no\"],\n",
    "        \"purch_doc_item_no_src_po\":       [\"purch_doc_item_no_src_po\", \"po_item\", \"item_no\"],\n",
    "        \"purch_doc_type_hpd_po\":          [\"purch_doc_type_hpd_po\", \"purch_doc_type\", \"doc_type\"],\n",
    "        \"release_indicator_hpd_po\":       [\"release_indicator_hpd_po\", \"release_indicator\", \"rel_ind\", \"rel_ind_hpd_po\"],\n",
    "        \"doc_change_date_hpd_po\":         [\"doc_change_date_hpd_po\", \"doc_change_date\"],\n",
    "        \"purch_doc_date_hpd_po\":          [\"purch_doc_date_hpd_po\", \"purch_doc_date\", \"po_date\"],\n",
    "        \"vendor_or_creditor_acct_no_hpd_po\": [\"vendor_or_creditor_acct_no_hpd_po\", \"vendor_code\", \"vendor_id\"],\n",
    "        \"vendor_name_1\":                  [\"vendor_name_1\", \"vendor_name\"],\n",
    "        \"material_no_src_po\":             [\"material_no_src_po\", \"material_code\", \"material\"],\n",
    "        \"short_text_src_po\":              [\"short_text_src_po\", \"short_text\", \"item_desc\", \"description\"],\n",
    "        \"order_uom_src_po\":               [\"order_uom_src_po\", \"uom\"],\n",
    "        \"quantity_src_po\":                [\"quantity_src_po\", \"qty\", \"quantity\"],\n",
    "        \"net_val_po_curr_src_po\":         [\"net_val_po_curr_src_po\", \"net_value\", \"net_val\"],\n",
    "        \"gross_val_po_curr_src_po\":       [\"gross_val_po_curr_src_po\", \"gross_value\", \"gross_val\"],\n",
    "        \"currency_hpd_po\":                [\"currency_hpd_po\", \"currency\", \"curr\"],\n",
    "        \"company_code_hpd_po\":            [\"company_code_hpd_po\", \"company_code\", \"bukrs\"],\n",
    "        \"plant_src_po\":                   [\"plant_src_po\", \"plant\", \"werk\"],\n",
    "        \"purch_org_hpd_po\":               [\"purch_org_hpd_po\", \"purch_org\", \"ekorg\"],\n",
    "        \"requester_name_src_po\":          [\"requester_name_src_po\", \"requestor_name\", \"requester_name\"],\n",
    "        \"po_item_del_flag_src_po\":        [\"po_item_del_flag_src_po\", \"deletion_indicator\", \"del_flag\"],\n",
    "        \"pr_no_src_po\":                   [\"pr_no_src_po\", \"pr_no\", \"purchase_req_no\"],\n",
    "        \"pr_item_no_src_po\":              [\"pr_item_no_src_po\", \"pr_item\", \"pr_item_no\", \"purchase_req_item\", \"preq_item\"],\n",
    "        \"matl_group_src_po\":              [\"matl_group_src_po\", \"material_group\", \"mat_group\", \"matl_group\"],\n",
    "        \"net_price_doc_curr_src_po\":      [\"net_price_doc_curr_src_po\", \"net_unit_price\", \"unit_price\", \"price\", \"unit_rate\"],\n",
    "        \"base_id_src_po\":                 [\"base_id_src_po\", \"base_id\", \"id_src\"],\n",
    "        \"material_type_src_po\":           [\"material_type_src_po\", \"material_type\", \"mat_type\", \"mtart\"],\n",
    "        \"on_release_total_value_hpd_po\":  [\"on_release_total_value_hpd_po\", \"on_release_total_value\", \"po_total_value\", \"total_po_value\"],\n",
    "        \"doc_change_date_src_po\":         [\"doc_change_date_src_po\", \"doc_change_date_src\"],}\n",
    "    \n",
    "    def _first_present(df, names):\n",
    "        m = {c.lower(): c for c in df.columns}\n",
    "        for n in names:\n",
    "            if n.lower() in m:\n",
    "                return m[n.lower()]\n",
    "        return None\n",
    "    \n",
    "    def standardize(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Ensure canonical columns exist and compute net unit price if missing.\"\"\"\n",
    "        df = df.copy()\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "        # synonyms -> canonical\n",
    "        for canon, variants in COL_SYNONYMS.items():\n",
    "            if canon not in df.columns:\n",
    "                src = _first_present(df, variants)\n",
    "                if src is not None:\n",
    "                    df[canon] = df[src]\n",
    "        # derive unit price if missing\n",
    "        if \"net_price_doc_curr_src_po\" not in df.columns or df[\"net_price_doc_curr_src_po\"].isna().all():\n",
    "            nv_col = _first_present(df, COL_SYNONYMS[\"net_val_po_curr_src_po\"])\n",
    "            q_col  = _first_present(df, COL_SYNONYMS[\"quantity_src_po\"])\n",
    "            if nv_col and q_col:\n",
    "                nv  = pd.to_numeric(df[nv_col], errors=\"coerce\")\n",
    "                qty = pd.to_numeric(df[q_col], errors=\"coerce\").replace({0: np.nan})\n",
    "                df[\"net_price_doc_curr_src_po\"] = nv / qty\n",
    "            else:\n",
    "                df[\"net_price_doc_curr_src_po\"] = np.nan\n",
    "        df[\"net_price_doc_curr_src_po\"]=pd.to_numeric(df[\"net_price_doc_curr_src_po\"], errors=\"coerce\")\n",
    "        df[\"net_val_po_curr_src_po\"]=pd.to_numeric(df[\"net_val_po_curr_src_po\"], errors=\"coerce\")\n",
    "        df[\"gross_val_po_curr_src_po\"]=pd.to_numeric(df[\"gross_val_po_curr_src_po\"], errors=\"coerce\")\n",
    "        df[\"on_release_total_value_hpd_po\"]=pd.to_numeric(df[\"on_release_total_value_hpd_po\"], errors=\"coerce\")\n",
    "        df[\"exchange_rate_hpd_po\"]=pd.to_numeric(df[\"exchange_rate_hpd_po\"], errors=\"coerce\")\n",
    "        df['net_price_doc_curr_src_po_with_exchange_rate']=df[\"net_price_doc_curr_src_po\"]*df[\"exchange_rate_hpd_po\"]\n",
    "        df['net_val_po_curr_src_po_with_exchange_rate']=df[\"net_val_po_curr_src_po\"]*df[\"exchange_rate_hpd_po\"]\n",
    "        df['gross_val_po_curr_src_po_with_exchange_rate']=df[\"gross_val_po_curr_src_po\"]*df[\"exchange_rate_hpd_po\"]\n",
    "        df['on_release_total_value_hpd_po_with_exchange_rate']=df[\"on_release_total_value_hpd_po\"]*df[\"exchange_rate_hpd_po\"]\n",
    "        # ensure required columns exist\n",
    "        required = [\n",
    "            \"purch_doc_no_src_po\",\"purch_doc_item_no_src_po\",\"purch_doc_type_hpd_po\",\n",
    "            \"release_indicator_hpd_po\",\"doc_change_date_hpd_po\",\"purch_doc_date_hpd_po\",\n",
    "            \"vendor_or_creditor_acct_no_hpd_po\",\"vendor_name_1\",\n",
    "            \"material_no_src_po\",\"short_text_src_po\",\"matl_group_src_po\",\"material_type_src_po\",\n",
    "            \"order_uom_src_po\",\"quantity_src_po\",\"net_price_doc_curr_src_po\",\n",
    "            \"net_val_po_curr_src_po\",\"gross_val_po_curr_src_po\",\n",
    "            \"currency_hpd_po\",\"company_code_hpd_po\",\"po_item_del_flag_src_po\",\n",
    "            \"plant_src_po\",\"purch_org_hpd_po\",\n",
    "            \"pr_no_src_po\",\"pr_item_no_src_po\",\"base_id_src_po\",\"doc_change_date_src_po\",\n",
    "            \"on_release_total_value_hpd_po\",'net_price_doc_curr_src_po_with_exchange_rate','net_val_po_curr_src_po_with_exchange_rate',\n",
    "            'gross_val_po_curr_src_po_with_exchange_rate','on_release_total_value_hpd_po_with_exchange_rate',\n",
    "            # optional risk/impact fields (created empty if absent)\n",
    "            \"risk_score\",\"risk_level\",\"main_risk_scenario\",\"sub_risk_1\",\"sub_risk_2\",\n",
    "            \"impact_1\",\"impact_2\",\"impact_3\",\n",
    "        ]\n",
    "        for c in required:\n",
    "            if c not in df.columns:\n",
    "                df[c] = np.nan\n",
    "        return df\n",
    "    \n",
    "    # =====================================================\n",
    "    # LOW-LEVEL HELPERS\n",
    "    # =====================================================\n",
    "    def _clean(x):\n",
    "        if x is None or pd.isna(x): return \"\"\n",
    "        return str(x).strip()\n",
    "    \n",
    "    def _num(x):\n",
    "        try:\n",
    "            if x is None or (isinstance(x,str) and not x.strip()): return np.nan\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    \n",
    "    def _to_date(s):\n",
    "        if pd.isna(s): return pd.NaT\n",
    "        return pd.to_datetime(s, errors=\"coerce\")\n",
    "    \n",
    "    def _best_date(row):\n",
    "        dt = _to_date(row.get(\"purch_doc_date_hpd_po\"))\n",
    "        if pd.notna(dt):\n",
    "            return dt.normalize()\n",
    "        return pd.NaT\n",
    "    \n",
    "    def _date_str(dt):\n",
    "        return dt.date().isoformat() if pd.notna(dt) else \"-\"\n",
    "    \n",
    "    def _starts_with_4(s):\n",
    "        s = _clean(s)\n",
    "        return s.startswith(\"4\")\n",
    "    \n",
    "    def _is_deleted(flag):\n",
    "        f = _clean(flag).upper()\n",
    "        return f in {\"L\",\"X\"}\n",
    "    \n",
    "    def _is_subject_skip(flag):\n",
    "        return _clean(flag).upper() == \"L\"\n",
    "    \n",
    "    def _uom_price(row):\n",
    "        return _num(row.get(\"net_price_doc_curr_src_po_with_exchange_rate\"))\n",
    "    \n",
    "    def _within_days(a, b, days):\n",
    "        if pd.isna(a) or pd.isna(b): return False\n",
    "        return abs((a - b).days) <= int(days)\n",
    "    \n",
    "    def _delta_pct(ref_price, cmp_price):\n",
    "        \"\"\"\n",
    "        Your sign convention:\n",
    "          positive  => subject unit price > compared unit price\n",
    "          negative  => subject unit price < compared unit price\n",
    "        \"\"\"\n",
    "        if pd.isna(ref_price) or ref_price == 0 or pd.isna(cmp_price):\n",
    "            return np.nan\n",
    "        return 100.0 * (ref_price - cmp_price) / abs(ref_price)\n",
    "    \n",
    "    def _risk_score_2dp(x):\n",
    "        v = _num(x)\n",
    "        return \"-\" if pd.isna(v) else f\"{v:.2f}\"\n",
    "    \n",
    "    def _po_total_value(df, subject_row):\n",
    "        \"\"\"Compute total PO value (sum of net values for that PO). Fallback to on_release_total_value_hpd_po if present.\"\"\"\n",
    "        po  = _clean(subject_row.get(\"purch_doc_no_src_po\"))\n",
    "        #cur = _clean(subject_row.get(\"currency_hpd_po\")) or \"\"\n",
    "        cur = \"INR\"\n",
    "        if not po:\n",
    "            tv = _num(subject_row.get(\"on_release_total_value_hpd_po_with_exchange_rate\"))\n",
    "            return cur, (None if pd.isna(tv) else tv)\n",
    "        df_po = df[df[\"purch_doc_no_src_po\"].astype(str).str.strip() == po]\n",
    "        total_net = pd.to_numeric(df_po[\"net_val_po_curr_src_po_with_exchange_rate\"], errors=\"coerce\").sum()\n",
    "        if total_net and not pd.isna(total_net) and total_net > 0:\n",
    "            return cur, total_net\n",
    "        tv = _num(subject_row.get(\"on_release_total_value_hpd_po_with_exchange_rate\"))\n",
    "        return cur, (None if pd.isna(tv) else tv)\n",
    "    \n",
    "    def _opt_join(*vals):\n",
    "        got = [str(v).strip() for v in vals if v is not None and str(v).strip() and str(v).strip().lower() not in {\"none\",\"nan\"}]\n",
    "        return \", \".join(got)\n",
    "    \n",
    "    # =====================================================\n",
    "    # SUBJECT SELECTOR\n",
    "    # =====================================================\n",
    "    def select_subject_row(df, po_no=None, po_item=None, base_id=None, idx=None):\n",
    "        d = standardize(df)\n",
    "        if idx is not None:\n",
    "            return d.iloc[int(idx)]\n",
    "        if base_id:\n",
    "            m = d[d[\"base_id_src_po\"].astype(str).str.strip() == _clean(base_id)]\n",
    "            if len(m): return m.iloc[0]\n",
    "        if po_no and po_item:\n",
    "            m = d[(d[\"purch_doc_no_src_po\"].astype(str).str.strip()==_clean(po_no)) &\n",
    "                  (d[\"purch_doc_item_no_src_po\"].astype(str).str.strip()==_clean(po_item))]\n",
    "            if len(m): return m.iloc[0]\n",
    "        raise ValueError(\"Subject not found. Provide (po_no & po_item) or base_id or idx.\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # BASE FILTERS FOR RULES (ONLY release_indicator_hpd_po == 'R')\n",
    "    # =====================================================\n",
    "    def _released_only(df):\n",
    "        return df[df[\"release_indicator_hpd_po\"].astype(str).str.upper() == \"R\"].copy()\n",
    "    \n",
    "    def _base_filter_common(df):\n",
    "        out = _released_only(df)\n",
    "        out = out[out[\"material_no_src_po\"].astype(str).str.strip() != \"\"]\n",
    "        out = out[~out[\"po_item_del_flag_src_po\"].apply(_is_deleted)]\n",
    "        out = out[~out[\"plant_src_po\"].apply(_starts_with_4)]\n",
    "        return out\n",
    "    \n",
    "    def _filter_for_67(df):\n",
    "        out = _base_filter_common(df)\n",
    "        out = out[~out[\"purch_doc_type_hpd_po\"].isin(DOC_TYPE_EXCLUDE_6768)]\n",
    "        return out\n",
    "    \n",
    "    def _filter_for_68(df):\n",
    "        out = _base_filter_common(df)\n",
    "        out = out[~out[\"purch_doc_type_hpd_po\"].isin(DOC_TYPE_EXCLUDE_6768)]\n",
    "        return out\n",
    "    \n",
    "    def _filter_for_70(df):\n",
    "        out = _released_only(df)\n",
    "        out = out[~out[\"purch_doc_type_hpd_po\"].isin(DOC_TYPE_EXCLUDE_70)]\n",
    "        out = out[~out[\"po_item_del_flag_src_po\"].apply(_is_deleted)]\n",
    "        out = out[~out[\"plant_src_po\"].apply(_starts_with_4)]\n",
    "        gv = pd.to_numeric(out[\"gross_val_po_curr_src_po_with_exchange_rate\"], errors=\"coerce\")\n",
    "        nv = pd.to_numeric(out[\"net_val_po_curr_src_po_with_exchange_rate\"], errors=\"coerce\")\n",
    "        out = out[gv.fillna(nv).fillna(0) >= 0.0]\n",
    "        return out\n",
    "    \n",
    "    def _norm_keys(df):\n",
    "        b = df.copy()\n",
    "        for c in [\n",
    "            \"vendor_or_creditor_acct_no_hpd_po\",\"company_code_hpd_po\",\"currency_hpd_po\",\n",
    "            \"material_no_src_po\",\"short_text_src_po\",\"purch_doc_no_src_po\",\"purch_doc_item_no_src_po\",\n",
    "            \"pr_no_src_po\",\"pr_item_no_src_po\"\n",
    "        ]:\n",
    "            if c in b.columns:\n",
    "                b[c] = b[c].astype(str).str.strip()\n",
    "        return b\n",
    "    \n",
    "    \n",
    "    \n",
    "    def comps_67(subject, df) -> pd.DataFrame:\n",
    "        base = _filter_for_67(df)\n",
    "        b = _norm_keys(base)\n",
    "        vendor = _clean(subject.get(\"vendor_or_creditor_acct_no_hpd_po\"))\n",
    "        mat    = _clean(subject.get(\"material_no_src_po\"))\n",
    "        cur    = _clean(subject.get(\"currency_hpd_po\"))\n",
    "        if not vendor or not mat:\n",
    "            return pd.DataFrame()\n",
    "        cond = (b[\"vendor_or_creditor_acct_no_hpd_po\"] == vendor) & (b[\"material_no_src_po\"] == mat)\n",
    "        #if CURRENCY_MUST_MATCH and cur:\n",
    "            #cond = cond & (b[\"currency_hpd_po\"] == cur)\n",
    "        cand = b[cond].copy()\n",
    "        # drop same line\n",
    "        cand = cand[~(\n",
    "            (cand[\"purch_doc_no_src_po\"] == _clean(subject[\"purch_doc_no_src_po\"])) &\n",
    "            (cand[\"purch_doc_item_no_src_po\"] == _clean(subject[\"purch_doc_item_no_src_po\"]))\n",
    "        )]\n",
    "        cand[\"__date\"]  = cand.apply(_best_date, axis=1)\n",
    "        cand[\"__price\"] = pd.to_numeric(cand['net_price_doc_curr_src_po_with_exchange_rate'], errors=\"coerce\")\n",
    "        cand[\"__delta_pct\"] = cand[\"__price\"].apply(lambda up: _delta_pct(_uom_price(subject), up))\n",
    "        cand = cand.dropna(subset=[\"__price\"])\n",
    "        cand = cand[cand[\"__delta_pct\"].abs() != EPS_ZERO_DELTA_PCT]\n",
    "        cand=cand.sort_values(by=[\"__delta_pct\"],ascending=False)\n",
    "        return cand\n",
    "    \n",
    "    def comps_68(subject, df) -> pd.DataFrame:\n",
    "        base = _filter_for_68(df)\n",
    "        b = _norm_keys(base)\n",
    "        vendor = _clean(subject.get(\"vendor_or_creditor_acct_no_hpd_po\"))\n",
    "        mat    = _clean(subject.get(\"material_no_src_po\"))\n",
    "        cur    = _clean(subject.get(\"currency_hpd_po\"))\n",
    "        if not mat:\n",
    "            return pd.DataFrame()\n",
    "        cond = (b[\"material_no_src_po\"] == mat)\n",
    "        #if CURRENCY_MUST_MATCH and cur:\n",
    "            #cond = cond & (b[\"currency_hpd_po\"] == cur)\n",
    "        if vendor:\n",
    "            cond = cond & (b[\"vendor_or_creditor_acct_no_hpd_po\"] != vendor)\n",
    "        cand = b[cond].copy()\n",
    "        cand = cand[~(\n",
    "            (cand[\"purch_doc_no_src_po\"] == _clean(subject[\"purch_doc_no_src_po\"])) &\n",
    "            (cand[\"purch_doc_item_no_src_po\"] == _clean(subject[\"purch_doc_item_no_src_po\"]))\n",
    "        )]\n",
    "        cand[\"__date\"]  = cand.apply(_best_date, axis=1)\n",
    "        cand[\"__price\"] = pd.to_numeric(cand['net_price_doc_curr_src_po_with_exchange_rate'], errors=\"coerce\")\n",
    "        cand[\"__delta_pct\"] = cand[\"__price\"].apply(lambda up: _delta_pct(_uom_price(subject), up))\n",
    "        cand = cand.dropna(subset=[\"__price\"])\n",
    "        cand = cand[cand[\"__delta_pct\"].abs() != EPS_ZERO_DELTA_PCT]\n",
    "        cand=cand.sort_values(by=[\"__delta_pct\"],ascending=False)\n",
    "        return cand\n",
    "    \n",
    "    def comps_70(subject, df) -> pd.DataFrame:\n",
    "        base = _filter_for_70(df)\n",
    "        b = _norm_keys(base)\n",
    "        vendor = _clean(subject.get(\"vendor_or_creditor_acct_no_hpd_po\"))\n",
    "        cc     = _clean(subject.get(\"company_code_hpd_po\"))\n",
    "        cur    = _clean(subject.get(\"currency_hpd_po\"))\n",
    "        mat    = _clean(subject.get(\"material_no_src_po\"))\n",
    "        st     = _clean(subject.get(\"short_text_src_po\")).lower()\n",
    "        d0     = _best_date(subject)\n",
    "        if not (vendor and cc and cur and pd.notna(d0)):\n",
    "            return pd.DataFrame()\n",
    "        cond = (\n",
    "            (b[\"vendor_or_creditor_acct_no_hpd_po\"] == vendor) &\n",
    "            (b[\"company_code_hpd_po\"] == cc)# &\n",
    "            #(b[\"currency_hpd_po\"] == cur)\n",
    "        )\n",
    "        if mat:\n",
    "            cond = cond & (b[\"material_no_src_po\"] == mat)\n",
    "        else:\n",
    "            cond = cond & (b[\"short_text_src_po\"].str.lower() == st)\n",
    "        cand = b[cond].copy()\n",
    "        # different PO line\n",
    "        cand = cand[~(\n",
    "            (cand[\"purch_doc_no_src_po\"] == _clean(subject[\"purch_doc_no_src_po\"])) &\n",
    "            (cand[\"purch_doc_item_no_src_po\"] == _clean(subject[\"purch_doc_item_no_src_po\"])))]\n",
    "        # date window\n",
    "        cand[\"__date\"] = pd.to_datetime(cand[\"purch_doc_date_hpd_po\"], errors=\"coerce\")\n",
    "        m = cand[\"__date\"].isna()\n",
    "        cand.loc[m, \"__date\"] = pd.to_datetime(cand.loc[m, \"doc_change_date_hpd_po\"], errors=\"coerce\")\n",
    "        m = cand[\"__date\"].isna()\n",
    "        cand.loc[m, \"__date\"] = pd.to_datetime(cand.loc[m, \"doc_change_date_src_po\"], errors=\"coerce\")\n",
    "        cand = cand.dropna(subset=[\"__date\"])\n",
    "        lo, hi = d0 - pd.Timedelta(days=SPLIT_WINDOW_DAYS), d0 + pd.Timedelta(days=SPLIT_WINDOW_DAYS)\n",
    "        cand = cand[(cand[\"__date\"] >= lo) & (cand[\"__date\"] <= hi)]\n",
    "        # price/delta\n",
    "        cand[\"__price\"] = pd.to_numeric(cand['net_price_doc_curr_src_po_with_exchange_rate'], errors=\"coerce\")\n",
    "        cand[\"__delta_pct\"] = cand[\"__price\"].apply(lambda up: _delta_pct(_uom_price(subject), up))\n",
    "        cand = cand.dropna(subset=[\"__price\"])\n",
    "        cand=cand.sort_values(by=[\"__date\"],ascending=True)\n",
    "        return cand\n",
    "    \n",
    "    def comps_72(subject, df, strict_pr_item: bool = True) -> pd.DataFrame:\n",
    "        d = _released_only(standardize(df))\n",
    "        b = _norm_keys(d)\n",
    "        pr   = _clean(subject.get(\"pr_no_src_po\"))\n",
    "        prit = _clean(subject.get(\"pr_item_no_src_po\"))\n",
    "        if not pr:\n",
    "            return pd.DataFrame()\n",
    "        if strict_pr_item:\n",
    "            subset = b[(b[\"pr_no_src_po\"] == pr) & (b[\"pr_item_no_src_po\"] == prit)]\n",
    "        else:\n",
    "            subset = b[(b[\"pr_no_src_po\"] == pr)]\n",
    "        subset = subset[~(\n",
    "            (subset[\"purch_doc_no_src_po\"] == _clean(subject[\"purch_doc_no_src_po\"])) &\n",
    "            (subset[\"purch_doc_item_no_src_po\"] == _clean(subject[\"purch_doc_item_no_src_po\"])))]\n",
    "        subset = subset.copy()\n",
    "        subset[\"__date\"]  = subset.apply(_best_date, axis=1)\n",
    "        subset[\"__price\"] = pd.to_numeric(subset['net_price_doc_curr_src_po_with_exchange_rate'], errors=\"coerce\")\n",
    "        subset[\"__delta_pct\"] = subset[\"__price\"].apply(lambda up: _delta_pct(_uom_price(subject), up))\n",
    "        subset = subset.dropna(subset=[\"__price\"])\n",
    "        subset=subset.sort_values(by=[\"__date\"],ascending=True)\n",
    "        return subset\n",
    "    \n",
    "    # =====================================================\n",
    "    # BUSINESS IMPACT HELPERS\n",
    "    # =====================================================\n",
    "    def _format_money(cur, val):\n",
    "        if val is None or pd.isna(val): return \"-\"\n",
    "        try:\n",
    "            return f\"{cur} {val:,.2f}\".strip()\n",
    "        except Exception:\n",
    "            return f\"{cur} {val}\"\n",
    "    \n",
    "    def _header_share(row, df):\n",
    "        po = _clean(row.get(\"purch_doc_no_src_po\"))\n",
    "        #cur = _clean(row.get(\"currency_hpd_po\")) or \"\"\n",
    "        cur='INR'\n",
    "        line_val = _num(row.get(\"net_val_po_curr_src_po_with_exchange_rate\"))\n",
    "        if pd.isna(line_val):\n",
    "            line_val = _num(row.get(\"gross_val_po_curr_src_po_with_exchange_rate\"))\n",
    "        if not po or pd.isna(line_val):\n",
    "            return cur, line_val, None\n",
    "        header_sum = pd.to_numeric(df[df[\"purch_doc_no_src_po\"].astype(str) == po][\"net_val_po_curr_src_po_with_exchange_rate\"], errors=\"coerce\").sum()\n",
    "        if not header_sum or header_sum == 0:\n",
    "            return cur, line_val, None\n",
    "        return cur, line_val, round(100.0 * line_val / header_sum, 2)\n",
    "    \n",
    "    # =====================================================\n",
    "    # RENDER: Word-like 5 sections as Markdown tables\n",
    "    # =====================================================\n",
    "    def _fmt_inr(val, cur):\n",
    "        if pd.isna(val): return \"\"\n",
    "        try:\n",
    "            return f\"{cur} {float(val):,.2f}\".strip()\n",
    "        except Exception:\n",
    "            return f\"{cur} {val}\"\n",
    "    \n",
    "    def _fmt_pct(p):\n",
    "        if pd.isna(p): return \"\"\n",
    "        return f\"{p:+.1f}%\"\n",
    "    \n",
    "    def _qty_uom_price(row):\n",
    "        \"\"\"\n",
    "        Returns a single string exactly like:\n",
    "          \"<qty> <uom> @ <CUR> <unit_price>\"\n",
    "        Example: \"490 L @ INR 85.03\"\n",
    "        Falls back gracefully if some pieces are missing.\n",
    "        \"\"\"\n",
    "        qty = pd.to_numeric(row.get(\"quantity_src_po\"), errors=\"coerce\")\n",
    "        uom = _clean(row.get(\"order_uom_src_po\"))\n",
    "        #cur = (_clean(row.get(\"currency_hpd_po\")) or \"\").upper()\n",
    "        cur = \"INR\"\n",
    "        up  = _uom_price(row)\n",
    "    \n",
    "        def _fmt_qty(q):\n",
    "            if pd.isna(q):\n",
    "                return \"\"\n",
    "            s = f\"{float(q):.3f}\".rstrip(\"0\").rstrip(\".\")\n",
    "            return s\n",
    "    \n",
    "        qty_s = _fmt_qty(qty)\n",
    "        uom_s = uom\n",
    "        price_s = \"\" if pd.isna(up) else f\"{cur} {float(up):,.2f}\".strip()\n",
    "    \n",
    "        left = \" \".join([p for p in (qty_s, uom_s) if p])\n",
    "        right = price_s\n",
    "    \n",
    "        if left and right:\n",
    "            return f\"{left} @ {right}\"\n",
    "        elif left:\n",
    "            return left\n",
    "        elif right:\n",
    "            return right\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    def _subject_key_table(s, df_full):\n",
    "        #cur = _clean(s.get(\"currency_hpd_po\")) or \"\"\n",
    "        cur = \"INR\"\n",
    "        po   = _clean(s.get(\"purch_doc_no_src_po\"))\n",
    "        it   = _clean(s.get(\"purch_doc_item_no_src_po\"))\n",
    "        prn  = _clean(s.get(\"pr_no_src_po\"))\n",
    "        pri  = _clean(s.get(\"pr_item_no_src_po\"))\n",
    "        rel  =_clean(s.get(\"release_indicator_hpd_po\")) #change #_clean(s.get(\"on_release_total_value_hpd_po_with_exchange_rate\"))\n",
    "        ven  = _clean(s.get(\"vendor_or_creditor_acct_no_hpd_po\"))\n",
    "        venm = _clean(s.get(\"vendor_name_1\"))\n",
    "        mat  = _clean(s.get(\"material_no_src_po\"))\n",
    "        mtp  = _clean(s.get(\"material_type_src_po\"))\n",
    "        txt  = _clean(s.get(\"short_text_src_po\"))\n",
    "        plant= _clean(s.get(\"plant_src_po\"))\n",
    "        org  = _clean(s.get(\"purch_org_hpd_po\"))\n",
    "        req  = _clean(s.get(\"requester_name_src_po\"))\n",
    "        pdt  = _date_str(_best_date(s))\n",
    "        delF = _clean(s.get(\"po_item_del_flag_src_po\"))\n",
    "    \n",
    "        qty_price = _qty_uom_price(s)\n",
    "        netv = pd.to_numeric(s.get(\"net_val_po_curr_src_po_with_exchange_rate\"), errors=\"coerce\")\n",
    "        grossv = pd.to_numeric(s.get(\"gross_val_po_curr_src_po_with_exchange_rate\"), errors=\"coerce\")\n",
    "        cur_tv, total_po_val = _po_total_value(df_full, s)\n",
    "    \n",
    "        rows = [\n",
    "            (\"PO / Item & PR Ref\",      f\"{po} / {it} & PR {prn} / {pri}\".strip()),\n",
    "            (\"Release Status\",          rel),\n",
    "            (\"Vendor no - Name\",        f\"{ven} – {venm}\".strip(\" –\")),\n",
    "            (\"Material – Text, Type\",   f\"{mat} — {txt}, Type {mtp}\".strip(\" ,\")),\n",
    "            (\"Plant / Org\",             f\"{plant} / {org}\".strip(\" /\")),\n",
    "            (\"Requester\",               req),\n",
    "            (\"Purchase Date\",           pdt),\n",
    "            (\"Quantity / Unit & Unit Price\", qty_price),  # ← exact format \"490 L @ INR 85.03\"\n",
    "            (\"Net / Gross Value\",       _fmt_inr(netv if not pd.isna(netv) else grossv, cur)),\n",
    "            (\"Total PO Value\",          \"-\" if total_po_val is None else _fmt_inr(total_po_val, cur_tv)),\n",
    "            (\"Deletion Indicator\",      \"(blank)\" if not delF else delF),\n",
    "        ]\n",
    "        out = [\"| Field | Value |\", \"|---|---|\"]\n",
    "        out += [f\"| {k} | {v} |\" for k, v in rows]\n",
    "        return \"\\n\".join(out)\n",
    "    \n",
    "    def _risk_drivers_block(res, subject_row):\n",
    "        drivers = []\n",
    "        if len(res[\"rule_67\"][\"table\"]) > 0:\n",
    "            drivers.append(\"Price variance within same vendor.\")\n",
    "        if len(res[\"rule_68\"][\"table\"]) > 0:\n",
    "            drivers.append(\"Cross-vendor price variance.\")\n",
    "        if len(res[\"rule_70\"][\"table\"]) > 0:\n",
    "            drivers.append(\"Split POs (±60 days, same vendor/material).\")\n",
    "        if len(res[\"rule_72\"][\"table\"]) > 0:\n",
    "            drivers.append(\"Split POs PR-based (same PR line).\")\n",
    "        return drivers if drivers else [\"No Risk\"]\n",
    "    \n",
    "    def _variance_cols(comps_df, subject_row):\n",
    "        cur_up = _uom_price(subject_row)\n",
    "        qty = pd.to_numeric(subject_row.get(\"quantity_src_po\"), errors=\"coerce\")\n",
    "        df = comps_df.copy()\n",
    "        df[\"Δ vs Current\"] = df[\"__delta_pct\"].apply(_fmt_pct)                   # uses your sign convention\n",
    "        df[\"Variance Value/Unit\"] = cur_up - df[\"__price\"]                       # subject - compared\n",
    "        df[\"Variance Value\"] = np.where(pd.notna(qty), df[\"Variance Value/Unit\"] * qty, np.nan)\n",
    "        return df\n",
    "    \n",
    "    # UPDATED: return None (hide) when there are no rows and HIDE_NO_RISK_SUBSECTIONS=True\n",
    "    def _mk_rule_table(header_title, comps_df, subject_row, hide_no_risk=HIDE_NO_RISK_SUBSECTIONS):\n",
    "        if comps_df is None or len(comps_df) == 0:\n",
    "            if hide_no_risk:\n",
    "                return None\n",
    "            return f\"**{header_title}**\\n\\nNo Risk\\n\"\n",
    "        #cur = _clean(subject_row.get(\"currency_hpd_po\")) or \"\"\n",
    "        cur = \"INR\"\n",
    "        df = _variance_cols(comps_df, subject_row)\n",
    "        disp = pd.DataFrame({\n",
    "            \"PO → Item\": df[\"purch_doc_no_src_po\"].astype(str).str.strip() + \"/\" + df[\"purch_doc_item_no_src_po\"].astype(str).str.strip(),\n",
    "            \"Vendor\": df[\"vendor_or_creditor_acct_no_hpd_po\"].astype(str).str.strip(),\n",
    "            \"Price\": df[\"__price\"].apply(lambda v: _fmt_inr(v, cur)).astype(str),\n",
    "            \"Qty\": df.get(\"quantity_src_po\", pd.Series(index=df.index)).astype(str).replace(\"nan\",\"\"),\n",
    "            \"Δ vs Current\": df[\"Δ vs Current\"].fillna(\"\"),\n",
    "            \"Variance Value/Unit\": df[\"Variance Value/Unit\"].apply(lambda v: \"\" if pd.isna(v) else f\"{v:,.2f}\").astype(str),\n",
    "            \"Variance Value\": df[\"Variance Value\"].apply(lambda v: \"\" if pd.isna(v) else f\"{v:,.2f}\").astype(str),\n",
    "            \"Date\": df[\"__date\"].apply(_date_str),\n",
    "            \"Material\": df[\"material_no_src_po\"].astype(str).str.strip(),\n",
    "            \"Text\": df[\"short_text_src_po\"].astype(str).str.strip(),\n",
    "            \"PR\": df[\"pr_no_src_po\"].astype(str).str.strip() + \"/\" + df[\"pr_item_no_src_po\"].astype(str).str.strip(),\n",
    "            \"Deletion Indicator\": df[\"po_item_del_flag_src_po\"].astype(str).str.strip().replace({\"nan\": \"\"}),\n",
    "        })\n",
    "        md = [f\"**{header_title}**\", \"\"]\n",
    "        md.append(\"| \" + \" | \".join(disp.columns) + \" |\")\n",
    "        md.append(\"|\" + \"|\".join([\"---\"] * len(disp.columns)) + \"|\")\n",
    "        for _, r in disp.iterrows():\n",
    "            md.append(\"| \" + \" | \".join(r.values) + \" |\")\n",
    "        md.append(\"\")\n",
    "        return \"\\n\".join(md)\n",
    "    \n",
    "    # =====================================================\n",
    "    # VERIFY & RENDER\n",
    "    # =====================================================\n",
    "    def verify_transaction_all(df_std: pd.DataFrame, po_no=None, po_item=None, base_id=None, idx=None,\n",
    "                               strict_pr_item_72: bool = True):\n",
    "        \"\"\"\n",
    "        Returns a dict with:\n",
    "          - 'Key Description' : Series\n",
    "          - 'skip_reason' : str | None (if subject has del flag L)\n",
    "          - 'rule_67'/'68'/'70'/'72' : {'lines': [...], 'table': DataFrame (comps)}\n",
    "          - 'df_full_std' : DataFrame (for totals)\n",
    "        \"\"\"\n",
    "        subject = select_subject_row(df_std, po_no=po_no, po_item=po_item, base_id=base_id, idx=idx)\n",
    "        skip_reason = \"Subject has deletion indicator 'L'.\" if _is_subject_skip(subject.get(\"po_item_del_flag_src_po\")) else None\n",
    "        if skip_reason:\n",
    "            empty = pd.DataFrame()\n",
    "            return {\n",
    "                \"Key Description\": subject,\n",
    "                \"skip_reason\": skip_reason,\n",
    "                \"rule_67\": {\"lines\": [], \"table\": empty},\n",
    "                \"rule_68\": {\"lines\": [], \"table\": empty},\n",
    "                \"rule_70\": {\"lines\": [], \"table\": empty},\n",
    "                \"rule_72\": {\"lines\": [], \"table\": empty},\n",
    "                \"df_full_std\": df_std,\n",
    "            }\n",
    "    \n",
    "        c67 = comps_67(subject, df_std)\n",
    "        c68 = comps_68(subject, df_std)\n",
    "        c70 = comps_70(subject, df_std)\n",
    "        c72 = comps_72(subject, df_std, strict_pr_item=strict_pr_item_72)\n",
    "    \n",
    "        out = {\n",
    "            \"Key Description\": subject,\n",
    "            \"skip_reason\": None,\n",
    "            \"rule_67\": {\"lines\": [], \"table\": c67},\n",
    "            \"rule_68\": {\"lines\": [], \"table\": c68},\n",
    "            \"rule_70\": {\"lines\": [], \"table\": c70},\n",
    "            \"rule_72\": {\"lines\": [], \"table\": c72},\n",
    "            \"df_full_std\": df_std,\n",
    "        }\n",
    "        return out\n",
    "    \n",
    "    def render_all_docstyle(result_dict, df_full=None):\n",
    "        \"\"\"\n",
    "        Returns a single markdown string with:\n",
    "          1. Context & Trigger\n",
    "          2. Key Description (two-col table)\n",
    "          3. Business Impact (bullets)\n",
    "          4. Risk Drivers (bullets / 'No Risk')\n",
    "          5. Compared Transactions (A/B/C/D subtables or 'No Risk')\n",
    "        \"\"\"\n",
    "        s = result_dict[\"Key Description\"]\n",
    "        if df_full is None:\n",
    "            df_full = result_dict.get(\"df_full_std\", pd.DataFrame([s]))\n",
    "    \n",
    "        # Section 1\n",
    "        score = _risk_score_2dp(s.get(\"risk_score\"))\n",
    "        risk_level = _clean(s.get(\"risk_level\")) or \"No Risk\"\n",
    "        main_scenario = _clean(s.get(\"main_risk_scenario\")) or \"No Risk\"\n",
    "        sub1 = _clean(s.get(\"sub_risk_1\")); sub2 = _clean(s.get(\"sub_risk_2\"))\n",
    "        subs = _opt_join(sub1, sub2)\n",
    "        sec1 = [\n",
    "            \"**1. Context & Trigger**\",\n",
    "            f\"Sara Risk Score: {score} → {risk_level}\",\n",
    "            f\"Risk Scenario: {main_scenario}\" + (f\" → **Sub-risk**: {subs}\" if subs else \"\"),\n",
    "            \"\"\n",
    "        ]\n",
    "    \n",
    "        # Section 2\n",
    "        sec2 = [\"**2. Key Description (PO Details)**\", _subject_key_table(s, df_full), \"\"]\n",
    "    \n",
    "        # Section 3 (skip vs normal)\n",
    "        if result_dict.get(\"skip_reason\"):\n",
    "            sec3 = [\"**3. Business Impact**\", \"Deletion indicator = L. This transaction is excluded from analysis.\", \"\"]\n",
    "            sec4 = [\"**4. Risk Drivers**\", \"No Risk\", \"\"]\n",
    "            sec5 = [\"**5. Compared Transactions**\", \"No Risk\", \"\"]\n",
    "            return \"\\n\".join(sec1 + sec2 + sec3 + sec4 + sec5)\n",
    "    \n",
    "        cur_s, line_val, _share = _header_share(s, df_full)\n",
    "        cur_tv, total_po_val = _po_total_value(df_full, s)\n",
    "        flagged = _fmt_inr(line_val, cur_s)\n",
    "        total   = \"-\" if total_po_val is None else _fmt_inr(total_po_val, cur_tv)\n",
    "        impacts = _opt_join(_clean(s.get(\"impact_1\")), _clean(s.get(\"impact_2\")), _clean(s.get(\"impact_3\")))\n",
    "        sec3 = [\"**3. Business Impact**\",\n",
    "                f\"Flagged Value: {flagged} out of PO total {total}.\",\n",
    "                f\"Impact Areas: {impacts}.\" if impacts else \"\",\n",
    "                \"\"]\n",
    "    \n",
    "        # Section 4\n",
    "        drivers = _risk_drivers_block(result_dict, s)\n",
    "        sec4 = [\"**4. Risk Drivers**\"] + [d for d in drivers if d] + [\"\"]\n",
    "    \n",
    "        # Section 5 (A/B/C/D)\n",
    "        c67 = result_dict[\"rule_67\"][\"table\"]\n",
    "        c68 = result_dict[\"rule_68\"][\"table\"]\n",
    "        c70 = result_dict[\"rule_70\"][\"table\"]\n",
    "        c72 = result_dict[\"rule_72\"][\"table\"]\n",
    "    \n",
    "        blocks = [\n",
    "            _mk_rule_table(\"A. Price Variance — Same Vendor & Material (vs current unit price)\", c67, s),\n",
    "            _mk_rule_table(\"B. Price Variance — Cross Vendor (Same Material)\", c68, s),\n",
    "            _mk_rule_table(f\"C. Split PO Activity (±{SPLIT_WINDOW_DAYS} Days, Same Vendor & Material)\", c70, s),\n",
    "            _mk_rule_table(\"D. Split PO PR-based (Same PR Line)\", c72, s),\n",
    "        ]\n",
    "        # Keep only those sub-sections that have evidence (non-None strings)\n",
    "        blocks = [b for b in blocks if b]\n",
    "    \n",
    "        if not blocks:\n",
    "            sec5 = [\"**5. Compared Transactions**\", \"No Risk\", \"\"]\n",
    "        else:\n",
    "            sec5 = [\"**5. Compared Transactions**\", *blocks]\n",
    "    \n",
    "        return \"\\n\".join(sec1 + sec2 + sec3 + sec4 + sec5)\n",
    "    \n",
    "    # =====================================================\n",
    "    # APPLY TO EACH ROW (keep inside DataFrame)\n",
    "    # =====================================================\n",
    "    def build_word_style_explanations(df_std: pd.DataFrame, dest_col: str = \"llm_explanation\"):\n",
    "        out = []\n",
    "        n = len(df_std)\n",
    "        #for i, (_, row) in enumerate(df_std.iterrows(), 1):\n",
    "        for _, row in df_std.iterrows():\n",
    "            try:\n",
    "                res = verify_transaction_all(\n",
    "                    df_std,\n",
    "                    po_no=str(row[\"purch_doc_no_src_po\"]).strip(),\n",
    "                    po_item=str(row[\"purch_doc_item_no_src_po\"]).strip(),\n",
    "                    strict_pr_item_72=True\n",
    "                )\n",
    "                out.append(render_all_docstyle(res, df_full=df_std))\n",
    "                #if i % 200 == 0:\n",
    "                #    print(f\"Processed {i}/{n} rows...\")\n",
    "            except Exception as e:\n",
    "                out.append(f\"ERROR for {row.get('purch_doc_no_src_po')}/{row.get('purch_doc_item_no_src_po')}: {e}\")\n",
    "        df_std[dest_col] = out\n",
    "        return df_std\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # =====================================================\n",
    "    # MAIN (example) — integrate with your DF\n",
    "    # =====================================================\n",
    "    if __name__ == \"__main__\":\n",
    "        # Replace 'a.copy()' with your actual DataFrame variable\n",
    "        df_full = final_result_df_2.copy()  # e.g., pd.read_pickle(...)\n",
    "    \n",
    "        # 1) Standardize once\n",
    "        df_std = standardize(df_full)\n",
    "    \n",
    "        # 2) Build Word-style 5-section explanations (Markdown tables) per row\n",
    "        df_std = build_word_style_explanations(df_std, dest_col=\"llm_explanation\")\n",
    "    \n",
    "        # 3) (Optional) Save:\n",
    "        # df_std.to_pickle(\"output_with_word_style_explanations.pkl\")\n",
    "        # df_std.to_csv(\"output_with_word_style_explanations.csv\", index=False)\n",
    "        # df_std.to_excel(\"output_with_word_style_explanations.xlsx\", index=False)\n",
    "\n",
    "    return df_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
